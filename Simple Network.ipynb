{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /home/endre/git/finance_ml/src\n",
      "Python: 3.6.1, TensorFlow:1.2.1, Keras:2.0.5\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import os\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "import keras;\n",
    "\n",
    "# *print (\"Current file path: {}\".format(os.path.dirname(os.path.realpath(__file__))))\n",
    "print (\"Current Working Directory: {}\".format(os.getcwd()))\n",
    "print(\"Python: {}, TensorFlow:{}, Keras:{}\".\\\n",
    "      format(platform.python_version(), tf.__version__, keras.__version__))\n",
    "\n",
    "random_seed = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pickled Features, Labels and Name of each Feature-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De-pickling features, labels and feature/label names..\n",
      "De-pickle took 1806.1965110246092 ms\n",
      "\n",
      "RangeNames/features/labels len: 71036/71036/71036\n",
      "\n",
      "Number of Features for each feature-array: 54\n",
      "Number of Labels for each label-array: 4\n"
     ]
    }
   ],
   "source": [
    "print (\"De-pickling features, labels and feature/label names..\")\n",
    "load_start = timer()\n",
    "\n",
    "# pickled = pickle.load(open(\"RangeNamesFeaturesAndLabels-mk1.pickle\", \"rb\"))\n",
    "# pickled = pickle.load(open(\"RangeNamesFeaturesAndLabels-smallSet-6stocks.pickle\", \"rb\"))\n",
    "pickled = pickle.load(open(\"RangeNamesFeaturesAndLabels-smallSet-50stocks.pickle\", \"rb\"))\n",
    "# pickled = pickle.load(open(\"RangeNamesFeaturesAndLabels-mediumset-unknownNumStocks.pickle\", \"rb\"))\n",
    "# pickled = pickle.load(open(\"RangeNamesFeaturesAndLabels-largeSet-1619stocks.pickle\", \"rb\"))\n",
    "\n",
    "load_millis = (timer()-load_start) * 1000\n",
    "print (\"De-pickle took {} ms\".format(load_millis))\n",
    "\n",
    "# {'rangeNames': rangeNames, 'features': features, 'labels': labels}\n",
    "rangeNames = pickled['rangeNames']\n",
    "features = pickled['features']\n",
    "labels = pickled['labels']\n",
    "print(\"\\nRangeNames/features/labels len: {}/{}/{}\".\\\n",
    "      format(len(rangeNames), len(features), len(labels)))\n",
    "numFeatures = len(features[0])\n",
    "print(\"\\nNumber of Features for each feature-array: {}\".format(numFeatures))\n",
    "print(\"Number of Labels for each label-array: {}\".format(len(labels[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split set into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 811.70 MB\n",
      "Memory usage: 811.70 MB\n",
      "Memory usage: 811.70 MB\n",
      "TRAIN RangeNames/features/labels len: 66310/66310/66310 - 93.35% of total\n",
      "TEST RangeNames/features/labels len: 4726/4726/4726 - 6.65% of total\n",
      "\n",
      "Total loaded features: 71036, trainFeatures + testFeatures:71036 - 100.0000%\n"
     ]
    }
   ],
   "source": [
    "import resource\n",
    "import gc\n",
    "def mem():\n",
    "    print('Memory usage: %2.2f MB' % round(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024.0,1))\n",
    "    \n",
    "mem()\n",
    "trainRangeNames = []\n",
    "trainFeatures = []\n",
    "trainLabels = []\n",
    "\n",
    "testRangeNames = []\n",
    "testFeatures = []\n",
    "testLabels = []\n",
    "mem()\n",
    "\n",
    "gc.collect()\n",
    "mem()\n",
    "\n",
    "length = len(rangeNames)\n",
    "for i in range(length):\n",
    "    names = rangeNames[i]\n",
    "    if (names[1] < '2016-01-01'):\n",
    "        trainRangeNames.append(names)\n",
    "        trainFeatures.append(features[i])\n",
    "        trainLabels.append(labels[i])\n",
    "    else:\n",
    "        testRangeNames.append(names)\n",
    "        testFeatures.append(features[i])\n",
    "        testLabels.append(labels[i])\n",
    "\n",
    "lenTrainFeatures = len(trainFeatures)\n",
    "\n",
    "print(\"TRAIN RangeNames/features/labels len: {}/{}/{} - {:.2f}% of total\".\\\n",
    "      format(len(trainRangeNames), lenTrainFeatures, len(trainLabels), (lenTrainFeatures / len(features)) * 100 ))\n",
    "print(\"TEST RangeNames/features/labels len: {}/{}/{} - {:.2f}% of total\".\\\n",
    "      format(len(testRangeNames), len(testFeatures), len(testLabels), (len(testFeatures) / len(features)) * 100 ))\n",
    "\n",
    "print(\"\\nTotal loaded features: {}, trainFeatures + testFeatures:{} - {:.4f}%\".\\\n",
    "      format(len(features), lenTrainFeatures + len(testFeatures), ((lenTrainFeatures + len(testFeatures)) / len(features)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hotted ok.\n",
      "Train labels [good, bad]: [35957, 30353] -> [54.23%, 45.77%]\n",
      "Test labels  [good, bad]: [2849, 1877] -> [60.28%, 39.72%]\n"
     ]
    }
   ],
   "source": [
    "# One-hot the labels\n",
    "\n",
    "# 0:  5 days\n",
    "# 1: 10 days\n",
    "# 2: 15 days\n",
    "# 3: 20 days\n",
    "label_to_use = 3\n",
    "\n",
    "good = [1,0]\n",
    "bad =  [0,1]\n",
    "\n",
    "trainLabels_onehot = [good if x[label_to_use] > 0 else bad  for x in trainLabels]\n",
    "testLabels_onehot = [good if x[label_to_use] > 0 else bad  for x in testLabels]\n",
    "print(\"One-hotted ok.\")\n",
    "\n",
    "sum_trainLabels = [sum(i) for i in zip(*trainLabels_onehot)]\n",
    "sum_testLabels = [sum(i) for i in zip(*testLabels_onehot)]\n",
    "print(\"Train labels [good, bad]: {} -> [{:.2f}%, {:.2f}%]\".\\\n",
    "      format(sum_trainLabels, (sum_trainLabels[0] / len(trainLabels)) * 100, (sum_trainLabels[1] / len(trainLabels)) * 100))\n",
    "print(\"Test labels  [good, bad]: {} -> [{:.2f}%, {:.2f}%]\".\\\n",
    "      format(sum_testLabels, (sum_testLabels[0] / len(testLabels)) * 100, (sum_testLabels[1] / len(testLabels)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !! RUN FROM HERE WHEN ONLY TWEAKING NETWORK !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "currentTrainPos = 0\n",
    "current_shuffle = 0\n",
    "shuff_trainFeatures = []\n",
    "shuff_trainLabels_onehot = []\n",
    "def getTrainMiniBatch(miniBatchSize):\n",
    "    global currentTrainPos, current_shuffle\n",
    "    global shuff_trainFeatures, shuff_trainLabels_onehot\n",
    "    # If we'll overflow the features list with this mini_batch, then reset the start position\n",
    "    if (currentTrainPos + miniBatchSize > lenTrainFeatures):\n",
    "        currentTrainPos = 0\n",
    "\n",
    "    # If the start position is 0, then run shuffling of features and labels.\n",
    "    if (currentTrainPos == 0):\n",
    "        print(\"Shuffling training features and labels - {}..\".format(current_shuffle))\n",
    "        shuff_trainFeatures, shuff_trainLabels_onehot = shuffle(trainFeatures, trainLabels_onehot, random_state=current_shuffle)\n",
    "        current_shuffle += 1\n",
    "\n",
    "    # Pick out the desired mini_batch size.\n",
    "    start = currentTrainPos\n",
    "    end = currentTrainPos + miniBatchSize\n",
    "    # .. store this mini_batch end pos as the next mini_batch start pos.\n",
    "    currentTrainPos = end\n",
    "    \n",
    "    # return np.array(shuff_trainFeatures[start:end]) / 100.0, np.array(shuff_trainLabels_onehot[start:end])\n",
    "    return shuff_trainFeatures[start:end], shuff_trainLabels_onehot[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini batches per epoch: trainFeats 66310 / mini_batch_size 128 = 518\n",
      "Total mini batches: mini_batches_per_epoch 518 * epochs 100 = 51800\n",
      "Network set up.\n"
     ]
    }
   ],
   "source": [
    "n1=800\n",
    "n2=1600\n",
    "n3=800\n",
    "# n4=600\n",
    "out=2\n",
    "epochs = 100 # Not explicitly used, as we count mini_batches\n",
    "mini_batch_size = 128\n",
    "learning_rate = 0.001  # 0.0001 is good, but maybe use higher learning rate when dropout'ing..\n",
    "keep_prob_in_train = 1\n",
    "keep_prob_hid_train = 1\n",
    "transfer_function = tf.nn.relu\n",
    "l2_regularization_beta = 0 # This seemed good, but currently having all softmaxed_test_Y to [ 0.53961992,  0.46038002]: 0.025\n",
    "\n",
    "#========\n",
    "mini_batches_per_epoch = int(lenTrainFeatures / mini_batch_size)\n",
    "total_mini_batches = mini_batches_per_epoch * epochs\n",
    "\n",
    "print(\"Mini batches per epoch: trainFeats {} / mini_batch_size {} = {}\".format(lenTrainFeatures, mini_batch_size, mini_batches_per_epoch))\n",
    "print(\"Total mini batches: mini_batches_per_epoch {} * epochs {} = {}\".format(mini_batches_per_epoch, epochs, total_mini_batches))\n",
    "\n",
    "# Reset the default graph, so as to chuck out existing variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope(\"input\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, numFeatures], name=\"X\")\n",
    "    keep_prob_in = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "    X_drop = tf.nn.dropout(X, keep_prob_in)\n",
    "    labels = tf.placeholder(tf.float32, shape=[None, out], name=\"labels\")\n",
    "\n",
    "with tf.variable_scope(\"hidden_layers_common\"):\n",
    "    keep_prob_hid = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "def weight_variable(name, shape):\n",
    "    # return tf.get_variable(name, initializer=tf.glorot_uniform_initializer(seed=random_seed), shape=shape)\n",
    "    return tf.get_variable(name, initializer=tf.contrib.layers.xavier_initializer(), shape=shape)\n",
    "    \n",
    "def bias_variable(name, shape):\n",
    "    # return tf.get_variable(name, initializer=tf.glorot_uniform_initializer(seed=random_seed), shape=shape)\n",
    "    # return tf.get_variable(name, initializer=tf.contrib.layers.xavier_initializer(), shape=shape)\n",
    "    return tf.get_variable(name, initializer=tf.constant_initializer(0.1), shape=shape)\n",
    "\n",
    "with tf.variable_scope(\"layer1\"):\n",
    "    w1 = weight_variable(\"weight\", [numFeatures, n1])\n",
    "    b1 = bias_variable(\"bias\", [n1])\n",
    "    l1 = tf.matmul(X_drop, w1) + b1\n",
    "    l1 = transfer_function(l1)\n",
    "    l1 = tf.nn.dropout(l1, keep_prob_hid)\n",
    "\n",
    "with tf.variable_scope(\"layer2\"):\n",
    "    w2 = weight_variable(\"weight\", [n1, n2])\n",
    "    b2 = bias_variable(\"bias\", [n2])\n",
    "    l2 = tf.matmul(l1, w2) + b2\n",
    "    l2 = transfer_function(l2)\n",
    "    l2 = tf.nn.dropout(l2, keep_prob_hid)\n",
    "\n",
    "with tf.variable_scope(\"layer3\"):\n",
    "    w3 = weight_variable(\"weight\", [n2, n3])\n",
    "    b3 = bias_variable(\"bias\", [n3])\n",
    "    l3 = tf.matmul(l2, w3) + b3\n",
    "    l3 = transfer_function(l3)\n",
    "    l3 = tf.nn.dropout(l3, keep_prob_hid)\n",
    "\n",
    "#with tf.variable_scope(\"layer4\"):\n",
    "#    w4 = weight_variable(\"weight\", [n3, n4])\n",
    "#    b4 = bias_variable(\"bias\", [n4])\n",
    "#    l4 = tf.matmul(l3, w4) + b4\n",
    "#    l4 = transfer_function(l4)\n",
    "    # l4 = tf.nn.dropout(l4, keep_prob_hid)\n",
    "\n",
    "with tf.variable_scope(\"output\"):\n",
    "    wy = weight_variable(\"weight\", [n3, out])\n",
    "    by = bias_variable(\"bias\", [out])\n",
    "    Y = tf.matmul(l3, wy) + by\n",
    "\n",
    "# :: Loss function with L2 Regularization\n",
    "#l2_regularizer = tf.nn.l2_loss(w1) + tf.nn.l2_loss(w2) + tf.nn.l2_loss(w3) + \\\n",
    "#                 tf.nn.l2_loss(w4) + tf.nn.l2_loss(wy)\n",
    "# NOTE: L1 regularizer: tf.reduce_sum(tf.abs(tensor)) instead of tf.nn.l2_loss(tensor)\n",
    "# Read here: https://github.com/tensorflow/models/blob/master/inception/inception/slim/losses.py\n",
    "# Max-norm:\n",
    "# https://stackoverflow.com/questions/37801832/how-can-i-implement-max-norm-constraints-in-an-mlp-in-tensorflow\n",
    "# Hmm..: https://stackoverflow.com/questions/34934303/renormalize-weight-matrix-using-tensorflow\n",
    "\n",
    "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Y, labels=labels) +\\\n",
    "#                      l2_regularization_beta * l2_regularizer)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Y, labels=labels))\n",
    "\n",
    "# :: Optimizer/Trainer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# Define Test/Evaluate: Accuracy: Fraction right predictions\n",
    "argmaxed_Y = tf.argmax(Y, 1)\n",
    "correct_prediction = tf.equal(argmaxed_Y, tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Make Softmax node, to use for evaluation\n",
    "softmaxed_Y = tf.nn.softmax(Y)\n",
    "\n",
    "print(\"Network set up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE Training\n",
      "  TRAIN cost/acc:3.0087/46.8049% [  26 4700], TEST cost/acc:3.0626/39.7799% [  15 4711]\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_length = len(testFeatures)\n",
    "check_trainFeatures, check_trainLabels_onehot = shuffle(trainFeatures, trainLabels_onehot, random_state=42)\n",
    "check_trainFeatures = check_trainFeatures[:check_length]\n",
    "check_trainLabels_onehot = check_trainLabels_onehot[:check_length]\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize TensorFlow variables in Session\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def printStats(what):\n",
    "    train_cost, train_accuracy, train_argmaxed_Y = sess.run([loss, accuracy, argmaxed_Y], \n",
    "                                       feed_dict={X: check_trainFeatures,\n",
    "                                                  labels: check_trainLabels_onehot,\n",
    "                                                  keep_prob_in: 1.0,\n",
    "                                                  keep_prob_hid: 1.0})\n",
    "    test_cost, test_accuracy, text_argmaxed_Y = sess.run([loss, accuracy, argmaxed_Y], \n",
    "                                     feed_dict={X: testFeatures,\n",
    "                                                labels: testLabels_onehot,\n",
    "                                                keep_prob_in: 1.0,\n",
    "                                                keep_prob_hid: 1.0})\n",
    "    _, train_counts = np.unique(train_argmaxed_Y, return_counts=True)\n",
    "    _, test_counts = np.unique(text_argmaxed_Y, return_counts=True)\n",
    "    print(\"{}\\n  TRAIN cost/acc:{:.4f}/{:.4f}% {}, TEST cost/acc:{:.4f}/{:.4f}% {}\"\\\n",
    "          .format(what, train_cost, train_accuracy*100, train_counts,\n",
    "                  test_cost, test_accuracy*100, test_counts))\n",
    "\n",
    "printStats(\"BEFORE Training\")\n",
    "print(\"-----------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.09142232,  2.47218537],\n",
       "       [-2.2506628 ,  2.4723506 ],\n",
       "       [-1.54527867,  2.98627281],\n",
       "       [-1.46618009,  3.928267  ],\n",
       "       [-1.70576215,  3.9822793 ],\n",
       "       [-1.6509701 ,  3.26231194],\n",
       "       [-1.12588501,  3.42122102],\n",
       "       [-1.3550725 ,  3.69757462],\n",
       "       [-1.23799002,  4.5408802 ],\n",
       "       [-0.3111079 ,  4.38337564],\n",
       "       [-1.09018695,  4.20815468],\n",
       "       [-0.78365612,  4.59549856],\n",
       "       [-2.31993842,  5.63417053],\n",
       "       [-0.71542501,  4.9671073 ],\n",
       "       [-1.10279167,  5.01119947],\n",
       "       [-1.51306736,  5.21146631],\n",
       "       [-1.5462954 ,  5.79684401],\n",
       "       [-2.65777969,  6.09949923],\n",
       "       [-2.08571243,  4.94816351],\n",
       "       [-1.16707909,  3.0348568 ]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cost, test_accuracy, test_Y, argmaxed_test_Y, softmaxed_test_Y = sess.run([loss, accuracy, Y, argmaxed_Y, softmaxed_Y], \n",
    "                                     feed_dict={X: testFeatures,\n",
    "                                                labels: testLabels_onehot,\n",
    "                                                keep_prob_in: 1.0,\n",
    "                                                keep_prob_hid: 1.0})\n",
    "test_Y[1010:1030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmaxed_test_Y[1010:1030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training features and labels - 0..\n",
      " ... progress: In \"Epoch\" 0 of 100, mini batch 100 of 51800\n",
      "  TRAIN cost/acc:0.7231/53.0258% [4682   44], TEST cost/acc:0.6876/60.0719% [4670   56]\n",
      " ... progress: In \"Epoch\" 0 of 100, mini batch 200 of 51800\n",
      "  TRAIN cost/acc:0.6892/53.6394% [3467 1259], TEST cost/acc:0.6909/56.1997% [3673 1053]\n",
      " ... progress: In \"Epoch\" 0 of 100, mini batch 300 of 51800\n",
      "  TRAIN cost/acc:0.7067/51.6293% [2394 2332], TEST cost/acc:0.6961/53.3220% [2095 2631]\n",
      " ... progress: In \"Epoch\" 0 of 100, mini batch 400 of 51800\n",
      "  TRAIN cost/acc:0.7087/51.8832% [2786 1940], TEST cost/acc:0.7036/52.8354% [3140 1586]\n",
      " ... progress: In \"Epoch\" 0 of 100, mini batch 500 of 51800\n",
      "  TRAIN cost/acc:0.6954/54.9090% [4059  667], TEST cost/acc:0.6836/58.2945% [4152  574]\n",
      "\n",
      "After \"Epoch\" 1 of 100, mini batch 518 of 51800\n",
      "  TRAIN cost/acc:0.6967/52.4122% [2141 2585], TEST cost/acc:0.7007/51.7562% [2101 2625]\n",
      "Shuffling training features and labels - 1..\n",
      " ... progress: In \"Epoch\" 1 of 100, mini batch 1000 of 51800\n",
      "\n",
      "After \"Epoch\" 2 of 100, mini batch 1036 of 51800\n",
      "  TRAIN cost/acc:0.6887/53.9780% [4589  137], TEST cost/acc:0.6792/59.8815% [4657   69]\n",
      "Shuffling training features and labels - 2..\n",
      " ... progress: In \"Epoch\" 2 of 100, mini batch 1500 of 51800\n",
      "\n",
      "After \"Epoch\" 3 of 100, mini batch 1554 of 51800\n",
      "  TRAIN cost/acc:0.6859/54.1261% [4608  118], TEST cost/acc:0.6780/59.9238% [4629   97]\n",
      "Shuffling training features and labels - 3..\n",
      " ... progress: In \"Epoch\" 3 of 100, mini batch 2000 of 51800\n",
      "\n",
      "After \"Epoch\" 4 of 100, mini batch 2072 of 51800\n",
      "  TRAIN cost/acc:0.6820/55.2687% [4350  376], TEST cost/acc:0.6813/58.7600% [4458  268]\n",
      "Shuffling training features and labels - 4..\n",
      " ... progress: In \"Epoch\" 4 of 100, mini batch 2500 of 51800\n",
      "\n",
      "After \"Epoch\" 5 of 100, mini batch 2590 of 51800\n",
      "  TRAIN cost/acc:0.6796/55.7977% [4259  467], TEST cost/acc:0.6822/58.6119% [4283  443]\n",
      "Shuffling training features and labels - 5..\n",
      " ... progress: In \"Epoch\" 5 of 100, mini batch 3000 of 51800\n",
      "\n",
      "After \"Epoch\" 6 of 100, mini batch 3108 of 51800\n",
      "  TRAIN cost/acc:0.6788/56.8980% [3515 1211], TEST cost/acc:0.6867/56.5595% [3522 1204]\n",
      "Shuffling training features and labels - 6..\n",
      " ... progress: In \"Epoch\" 6 of 100, mini batch 3500 of 51800\n",
      "\n",
      "After \"Epoch\" 7 of 100, mini batch 3626 of 51800\n",
      "  TRAIN cost/acc:0.6707/56.5171% [4051  675], TEST cost/acc:0.6849/58.6119% [3971  755]\n",
      "Shuffling training features and labels - 7..\n",
      " ... progress: In \"Epoch\" 7 of 100, mini batch 4000 of 51800\n",
      "\n",
      "After \"Epoch\" 8 of 100, mini batch 4144 of 51800\n",
      "  TRAIN cost/acc:0.6714/57.2577% [4000  726], TEST cost/acc:0.6875/57.7021% [3946  780]\n",
      "Shuffling training features and labels - 8..\n",
      " ... progress: In \"Epoch\" 8 of 100, mini batch 4500 of 51800\n",
      "\n",
      "After \"Epoch\" 9 of 100, mini batch 4662 of 51800\n",
      "  TRAIN cost/acc:0.6636/58.6542% [3692 1034], TEST cost/acc:0.6896/57.5328% [3748  978]\n",
      "Shuffling training features and labels - 9..\n",
      " ... progress: In \"Epoch\" 9 of 100, mini batch 5000 of 51800\n",
      "\n",
      "After \"Epoch\" 10 of 100, mini batch 5180 of 51800\n",
      "  TRAIN cost/acc:0.6566/59.1832% [3861  865], TEST cost/acc:0.6951/57.0673% [3766  960]\n",
      "Shuffling training features and labels - 10..\n",
      " ... progress: In \"Epoch\" 10 of 100, mini batch 5500 of 51800\n",
      "\n",
      "After \"Epoch\" 11 of 100, mini batch 5698 of 51800\n",
      "  TRAIN cost/acc:0.6443/60.1777% [3350 1376], TEST cost/acc:0.7095/55.1418% [3339 1387]\n",
      "Shuffling training features and labels - 11..\n",
      " ... progress: In \"Epoch\" 11 of 100, mini batch 6000 of 51800\n",
      "\n",
      "After \"Epoch\" 12 of 100, mini batch 6216 of 51800\n",
      "  TRAIN cost/acc:0.6348/61.4685% [3635 1091], TEST cost/acc:0.7127/55.9035% [3469 1257]\n",
      "Shuffling training features and labels - 12..\n",
      " ... progress: In \"Epoch\" 12 of 100, mini batch 6500 of 51800\n",
      "\n",
      "After \"Epoch\" 13 of 100, mini batch 6734 of 51800\n",
      "  TRAIN cost/acc:0.6299/61.4050% [3990  736], TEST cost/acc:0.7198/56.9192% [3879  847]\n",
      "Shuffling training features and labels - 13..\n",
      " ... progress: In \"Epoch\" 13 of 100, mini batch 7000 of 51800\n",
      "\n",
      "After \"Epoch\" 14 of 100, mini batch 7252 of 51800\n",
      "  TRAIN cost/acc:0.6014/63.9441% [3436 1290], TEST cost/acc:0.7631/55.8189% [3345 1381]\n",
      "Shuffling training features and labels - 14..\n",
      " ... progress: In \"Epoch\" 14 of 100, mini batch 7500 of 51800\n",
      "\n",
      "After \"Epoch\" 15 of 100, mini batch 7770 of 51800\n",
      "  TRAIN cost/acc:0.5955/64.5578% [3535 1191], TEST cost/acc:0.7684/56.1997% [3385 1341]\n",
      "Shuffling training features and labels - 15..\n",
      " ... progress: In \"Epoch\" 15 of 100, mini batch 8000 of 51800\n",
      "\n",
      "After \"Epoch\" 16 of 100, mini batch 8288 of 51800\n",
      "  TRAIN cost/acc:0.5730/66.0389% [3217 1509], TEST cost/acc:0.8477/52.1371% [3049 1677]\n",
      "Shuffling training features and labels - 16..\n",
      " ... progress: In \"Epoch\" 16 of 100, mini batch 8500 of 51800\n",
      "\n",
      "After \"Epoch\" 17 of 100, mini batch 8806 of 51800\n",
      "  TRAIN cost/acc:0.5562/67.4778% [3189 1537], TEST cost/acc:0.8707/53.4913% [3113 1613]\n",
      "Shuffling training features and labels - 17..\n",
      " ... progress: In \"Epoch\" 17 of 100, mini batch 9000 of 51800\n",
      "\n",
      "After \"Epoch\" 18 of 100, mini batch 9324 of 51800\n",
      "  TRAIN cost/acc:0.5511/67.6682% [3410 1316], TEST cost/acc:0.8582/54.1896% [3168 1558]\n",
      "Shuffling training features and labels - 18..\n",
      " ... progress: In \"Epoch\" 18 of 100, mini batch 9500 of 51800\n",
      "\n",
      "After \"Epoch\" 19 of 100, mini batch 9842 of 51800\n",
      "  TRAIN cost/acc:0.5080/71.0114% [3256 1470], TEST cost/acc:0.9606/53.3644% [3075 1651]\n",
      "Shuffling training features and labels - 19..\n",
      " ... progress: In \"Epoch\" 19 of 100, mini batch 10000 of 51800\n",
      "\n",
      "After \"Epoch\" 20 of 100, mini batch 10360 of 51800\n",
      "  TRAIN cost/acc:0.4955/71.4981% [3211 1515], TEST cost/acc:0.9791/54.0203% [3060 1666]\n",
      "Shuffling training features and labels - 20..\n",
      " ... progress: In \"Epoch\" 20 of 100, mini batch 10500 of 51800\n",
      "\n",
      "After \"Epoch\" 21 of 100, mini batch 10878 of 51800\n",
      "  TRAIN cost/acc:0.4880/71.6462% [3372 1354], TEST cost/acc:1.0276/54.1049% [3242 1484]\n",
      "Shuffling training features and labels - 21..\n",
      " ... progress: In \"Epoch\" 21 of 100, mini batch 11000 of 51800\n",
      "\n",
      "After \"Epoch\" 22 of 100, mini batch 11396 of 51800\n",
      "  TRAIN cost/acc:0.4617/74.2277% [3120 1606], TEST cost/acc:1.1510/53.5125% [3036 1690]\n",
      "Shuffling training features and labels - 22..\n",
      " ... progress: In \"Epoch\" 22 of 100, mini batch 11500 of 51800\n",
      "\n",
      "After \"Epoch\" 23 of 100, mini batch 11914 of 51800\n",
      "  TRAIN cost/acc:0.4479/75.2433% [3164 1562], TEST cost/acc:1.2004/53.3009% [3030 1696]\n",
      "Shuffling training features and labels - 23..\n",
      " ... progress: In \"Epoch\" 23 of 100, mini batch 12000 of 51800\n",
      "\n",
      "After \"Epoch\" 24 of 100, mini batch 12432 of 51800\n",
      "  TRAIN cost/acc:0.4197/76.5129% [3080 1646], TEST cost/acc:1.2792/53.4278% [2984 1742]\n",
      "Shuffling training features and labels - 24..\n",
      " ... progress: In \"Epoch\" 24 of 100, mini batch 12500 of 51800\n",
      "\n",
      "After \"Epoch\" 25 of 100, mini batch 12950 of 51800\n",
      "  TRAIN cost/acc:0.4115/76.8303% [3137 1589], TEST cost/acc:1.2415/53.0893% [3106 1620]\n",
      "Shuffling training features and labels - 25..\n",
      " ... progress: In \"Epoch\" 25 of 100, mini batch 13000 of 51800\n",
      "\n",
      "After \"Epoch\" 26 of 100, mini batch 13468 of 51800\n",
      "  TRAIN cost/acc:0.4181/77.5285% [3048 1678], TEST cost/acc:1.3370/53.7029% [3003 1723]\n",
      "Shuffling training features and labels - 26..\n",
      " ... progress: In \"Epoch\" 26 of 100, mini batch 13500 of 51800\n",
      "\n",
      "After \"Epoch\" 27 of 100, mini batch 13986 of 51800\n",
      "  TRAIN cost/acc:0.3817/78.7558% [3094 1632], TEST cost/acc:1.5242/53.8087% [3042 1684]\n",
      "Shuffling training features and labels - 27..\n",
      " ... progress: In \"Epoch\" 27 of 100, mini batch 14000 of 51800\n",
      " ... progress: In \"Epoch\" 27 of 100, mini batch 14500 of 51800\n",
      "\n",
      "After \"Epoch\" 28 of 100, mini batch 14504 of 51800\n",
      "  TRAIN cost/acc:0.3688/79.3060% [2984 1742], TEST cost/acc:1.5404/54.0203% [2818 1908]\n",
      "Shuffling training features and labels - 28..\n",
      " ... progress: In \"Epoch\" 28 of 100, mini batch 15000 of 51800\n",
      "\n",
      "After \"Epoch\" 29 of 100, mini batch 15022 of 51800\n",
      "  TRAIN cost/acc:0.3559/80.1523% [3032 1694], TEST cost/acc:1.4906/53.8087% [3028 1698]\n",
      "Shuffling training features and labels - 29..\n",
      " ... progress: In \"Epoch\" 29 of 100, mini batch 15500 of 51800\n",
      "\n",
      "After \"Epoch\" 30 of 100, mini batch 15540 of 51800\n",
      "  TRAIN cost/acc:0.3393/81.7181% [3066 1660], TEST cost/acc:1.6868/53.8722% [3019 1707]\n",
      "Shuffling training features and labels - 30..\n",
      " ... progress: In \"Epoch\" 30 of 100, mini batch 16000 of 51800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After \"Epoch\" 31 of 100, mini batch 16058 of 51800\n",
      "  TRAIN cost/acc:0.3440/81.2949% [3154 1572], TEST cost/acc:1.6021/53.8934% [3068 1658]\n",
      "Shuffling training features and labels - 31..\n",
      " ... progress: In \"Epoch\" 31 of 100, mini batch 16500 of 51800\n",
      "\n",
      "After \"Epoch\" 32 of 100, mini batch 16576 of 51800\n",
      "  TRAIN cost/acc:0.3312/82.5010% [3045 1681], TEST cost/acc:1.8111/53.9568% [3039 1687]\n",
      "Shuffling training features and labels - 32..\n",
      " ... progress: In \"Epoch\" 32 of 100, mini batch 17000 of 51800\n",
      "\n",
      "After \"Epoch\" 33 of 100, mini batch 17094 of 51800\n",
      "  TRAIN cost/acc:0.2949/84.6381% [2934 1792], TEST cost/acc:1.8307/52.8354% [2984 1742]\n",
      "Shuffling training features and labels - 33..\n",
      " ... progress: In \"Epoch\" 33 of 100, mini batch 17500 of 51800\n",
      "\n",
      "After \"Epoch\" 34 of 100, mini batch 17612 of 51800\n",
      "  TRAIN cost/acc:0.2982/84.5112% [2928 1798], TEST cost/acc:2.0100/53.1951% [2869 1857]\n",
      "Shuffling training features and labels - 34..\n",
      " ... progress: In \"Epoch\" 34 of 100, mini batch 18000 of 51800\n",
      "\n",
      "After \"Epoch\" 35 of 100, mini batch 18130 of 51800\n",
      "  TRAIN cost/acc:0.3049/83.9822% [2885 1841], TEST cost/acc:1.9946/53.6818% [2882 1844]\n",
      "Shuffling training features and labels - 35..\n",
      " ... progress: In \"Epoch\" 35 of 100, mini batch 18500 of 51800\n",
      "\n",
      "After \"Epoch\" 36 of 100, mini batch 18648 of 51800\n",
      "  TRAIN cost/acc:0.2723/85.5057% [2921 1805], TEST cost/acc:1.9990/52.4757% [2751 1975]\n",
      "Shuffling training features and labels - 36..\n",
      " ... progress: In \"Epoch\" 36 of 100, mini batch 19000 of 51800\n",
      "\n",
      "After \"Epoch\" 37 of 100, mini batch 19166 of 51800\n",
      "  TRAIN cost/acc:0.2792/85.8231% [2810 1916], TEST cost/acc:2.3414/53.0258% [2791 1935]\n",
      "Shuffling training features and labels - 37..\n",
      " ... progress: In \"Epoch\" 37 of 100, mini batch 19500 of 51800\n",
      "\n",
      "After \"Epoch\" 38 of 100, mini batch 19684 of 51800\n",
      "  TRAIN cost/acc:0.2709/86.0135% [2931 1795], TEST cost/acc:2.0271/53.0258% [2897 1829]\n",
      "Shuffling training features and labels - 38..\n",
      " ... progress: In \"Epoch\" 38 of 100, mini batch 20000 of 51800\n",
      "\n",
      "After \"Epoch\" 39 of 100, mini batch 20202 of 51800\n",
      "  TRAIN cost/acc:0.2529/86.9869% [2915 1811], TEST cost/acc:2.0942/54.1049% [2978 1748]\n",
      "Shuffling training features and labels - 39..\n",
      " ... progress: In \"Epoch\" 39 of 100, mini batch 20500 of 51800\n",
      "\n",
      "After \"Epoch\" 40 of 100, mini batch 20720 of 51800\n",
      "  TRAIN cost/acc:0.2536/86.9445% [2867 1859], TEST cost/acc:2.2426/54.8667% [2900 1826]\n",
      "Shuffling training features and labels - 40..\n",
      " ... progress: In \"Epoch\" 40 of 100, mini batch 21000 of 51800\n",
      "\n",
      "After \"Epoch\" 41 of 100, mini batch 21238 of 51800\n",
      "  TRAIN cost/acc:0.2553/87.0503% [2876 1850], TEST cost/acc:2.3716/53.3644% [2861 1865]\n",
      "Shuffling training features and labels - 41..\n",
      " ... progress: In \"Epoch\" 41 of 100, mini batch 21500 of 51800\n",
      "\n",
      "After \"Epoch\" 42 of 100, mini batch 21756 of 51800\n",
      "  TRAIN cost/acc:0.2834/85.8019% [2973 1753], TEST cost/acc:2.0521/52.9200% [2910 1816]\n",
      "Shuffling training features and labels - 42..\n",
      " ... progress: In \"Epoch\" 42 of 100, mini batch 22000 of 51800\n",
      "\n",
      "After \"Epoch\" 43 of 100, mini batch 22274 of 51800\n",
      "  TRAIN cost/acc:0.2326/87.9814% [2824 1902], TEST cost/acc:2.3785/53.9991% [2893 1833]\n",
      "Shuffling training features and labels - 43..\n",
      " ... progress: In \"Epoch\" 43 of 100, mini batch 22500 of 51800\n",
      "\n",
      "After \"Epoch\" 44 of 100, mini batch 22792 of 51800\n",
      "  TRAIN cost/acc:0.2434/87.4101% [2985 1741], TEST cost/acc:2.2858/52.7084% [3030 1696]\n",
      "Shuffling training features and labels - 44..\n",
      " ... progress: In \"Epoch\" 44 of 100, mini batch 23000 of 51800\n",
      "\n",
      "After \"Epoch\" 45 of 100, mini batch 23310 of 51800\n",
      "  TRAIN cost/acc:0.2181/89.3779% [2810 1916], TEST cost/acc:2.5242/54.1896% [2962 1764]\n",
      "Shuffling training features and labels - 45..\n",
      " ... progress: In \"Epoch\" 45 of 100, mini batch 23500 of 51800\n",
      "\n",
      "After \"Epoch\" 46 of 100, mini batch 23828 of 51800\n",
      "  TRAIN cost/acc:0.2343/88.3199% [2976 1750], TEST cost/acc:2.4222/53.9991% [3141 1585]\n",
      "Shuffling training features and labels - 46..\n",
      " ... progress: In \"Epoch\" 46 of 100, mini batch 24000 of 51800\n",
      "\n",
      "After \"Epoch\" 47 of 100, mini batch 24346 of 51800\n",
      "  TRAIN cost/acc:0.2228/89.4414% [2751 1975], TEST cost/acc:2.4086/53.9991% [2837 1889]\n",
      "Shuffling training features and labels - 47..\n",
      " ... progress: In \"Epoch\" 47 of 100, mini batch 24500 of 51800\n",
      "\n",
      "After \"Epoch\" 48 of 100, mini batch 24864 of 51800\n",
      "  TRAIN cost/acc:0.2030/89.7376% [2765 1961], TEST cost/acc:2.6193/52.7930% [2738 1988]\n",
      "Shuffling training features and labels - 48..\n",
      " ... progress: In \"Epoch\" 48 of 100, mini batch 25000 of 51800\n",
      "\n",
      "After \"Epoch\" 49 of 100, mini batch 25382 of 51800\n",
      "  TRAIN cost/acc:0.2084/89.6741% [2852 1874], TEST cost/acc:2.6648/53.8510% [2950 1776]\n",
      "Shuffling training features and labels - 49..\n",
      " ... progress: In \"Epoch\" 49 of 100, mini batch 25500 of 51800\n",
      "\n",
      "After \"Epoch\" 50 of 100, mini batch 25900 of 51800\n",
      "  TRAIN cost/acc:0.2205/88.9335% [2807 1919], TEST cost/acc:2.8033/52.2006% [2794 1932]\n",
      "Shuffling training features and labels - 50..\n",
      " ... progress: In \"Epoch\" 50 of 100, mini batch 26000 of 51800\n",
      "\n",
      "After \"Epoch\" 51 of 100, mini batch 26418 of 51800\n",
      "  TRAIN cost/acc:0.1843/91.0072% [2785 1941], TEST cost/acc:2.8225/52.1160% [2860 1866]\n",
      "Shuffling training features and labels - 51..\n",
      " ... progress: In \"Epoch\" 51 of 100, mini batch 26500 of 51800\n",
      "\n",
      "After \"Epoch\" 52 of 100, mini batch 26936 of 51800\n",
      "  TRAIN cost/acc:0.1897/90.6475% [2764 1962], TEST cost/acc:2.8138/53.5125% [2852 1874]\n",
      "Shuffling training features and labels - 52..\n",
      " ... progress: In \"Epoch\" 52 of 100, mini batch 27000 of 51800\n",
      "\n",
      "After \"Epoch\" 53 of 100, mini batch 27454 of 51800\n",
      "  TRAIN cost/acc:0.1802/91.0072% [2657 2069], TEST cost/acc:3.0090/52.7507% [2782 1944]\n",
      "Shuffling training features and labels - 53..\n",
      " ... progress: In \"Epoch\" 53 of 100, mini batch 27500 of 51800\n",
      "\n",
      "After \"Epoch\" 54 of 100, mini batch 27972 of 51800\n",
      "  TRAIN cost/acc:0.1777/91.2188% [2801 1925], TEST cost/acc:2.7297/52.9412% [2887 1839]\n",
      "Shuffling training features and labels - 54..\n",
      " ... progress: In \"Epoch\" 54 of 100, mini batch 28000 of 51800\n",
      "\n",
      "After \"Epoch\" 55 of 100, mini batch 28490 of 51800\n",
      "  TRAIN cost/acc:0.1929/90.7109% [2835 1891], TEST cost/acc:2.9350/53.8722% [3011 1715]\n",
      "Shuffling training features and labels - 55..\n",
      " ... progress: In \"Epoch\" 55 of 100, mini batch 28500 of 51800\n",
      " ... progress: In \"Epoch\" 55 of 100, mini batch 29000 of 51800\n",
      "\n",
      "After \"Epoch\" 56 of 100, mini batch 29008 of 51800\n",
      "  TRAIN cost/acc:0.1808/91.2188% [2767 1959], TEST cost/acc:2.9793/52.8354% [2662 2064]\n",
      "Shuffling training features and labels - 56..\n",
      " ... progress: In \"Epoch\" 56 of 100, mini batch 29500 of 51800\n",
      "\n",
      "After \"Epoch\" 57 of 100, mini batch 29526 of 51800\n",
      "  TRAIN cost/acc:0.1744/92.2556% [2640 2086], TEST cost/acc:2.9639/51.8832% [2615 2111]\n",
      "Shuffling training features and labels - 57..\n",
      " ... progress: In \"Epoch\" 57 of 100, mini batch 30000 of 51800\n",
      "\n",
      "After \"Epoch\" 58 of 100, mini batch 30044 of 51800\n",
      "  TRAIN cost/acc:0.1552/92.5518% [2696 2030], TEST cost/acc:2.9442/53.0047% [2826 1900]\n",
      "Shuffling training features and labels - 58..\n",
      " ... progress: In \"Epoch\" 58 of 100, mini batch 30500 of 51800\n",
      "\n",
      "After \"Epoch\" 59 of 100, mini batch 30562 of 51800\n",
      "  TRAIN cost/acc:0.1518/92.8269% [2701 2025], TEST cost/acc:3.1700/52.7084% [2800 1926]\n",
      "Shuffling training features and labels - 59..\n",
      " ... progress: In \"Epoch\" 59 of 100, mini batch 31000 of 51800\n",
      "\n",
      "After \"Epoch\" 60 of 100, mini batch 31080 of 51800\n",
      "  TRAIN cost/acc:0.1689/92.0863% [2738 1988], TEST cost/acc:3.1967/53.0681% [2851 1875]\n",
      "Shuffling training features and labels - 60..\n",
      " ... progress: In \"Epoch\" 60 of 100, mini batch 31500 of 51800\n",
      "\n",
      "After \"Epoch\" 61 of 100, mini batch 31598 of 51800\n",
      "  TRAIN cost/acc:0.1415/93.3771% [2699 2027], TEST cost/acc:3.0094/52.7084% [2812 1914]\n",
      "Shuffling training features and labels - 61..\n",
      " ... progress: In \"Epoch\" 61 of 100, mini batch 32000 of 51800\n",
      "\n",
      "After \"Epoch\" 62 of 100, mini batch 32116 of 51800\n",
      "  TRAIN cost/acc:0.1402/93.1020% [2726 2000], TEST cost/acc:3.1909/52.2429% [2840 1886]\n",
      "Shuffling training features and labels - 62..\n",
      " ... progress: In \"Epoch\" 62 of 100, mini batch 32500 of 51800\n",
      "\n",
      "After \"Epoch\" 63 of 100, mini batch 32634 of 51800\n",
      "  TRAIN cost/acc:0.1548/93.0808% [2689 2037], TEST cost/acc:3.2374/52.2218% [2649 2077]\n",
      "Shuffling training features and labels - 63..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... progress: In \"Epoch\" 63 of 100, mini batch 33000 of 51800\n",
      "\n",
      "After \"Epoch\" 64 of 100, mini batch 33152 of 51800\n",
      "  TRAIN cost/acc:0.1658/91.8536% [2755 1971], TEST cost/acc:3.0207/53.2374% [2847 1879]\n",
      "Shuffling training features and labels - 64..\n",
      " ... progress: In \"Epoch\" 64 of 100, mini batch 33500 of 51800\n",
      "\n",
      "After \"Epoch\" 65 of 100, mini batch 33670 of 51800\n",
      "  TRAIN cost/acc:0.1704/91.5996% [2809 1917], TEST cost/acc:3.2911/52.7084% [2994 1732]\n",
      "Shuffling training features and labels - 65..\n",
      " ... progress: In \"Epoch\" 65 of 100, mini batch 34000 of 51800\n",
      "\n",
      "After \"Epoch\" 66 of 100, mini batch 34188 of 51800\n",
      "  TRAIN cost/acc:0.1455/93.0597% [2708 2018], TEST cost/acc:3.1633/52.6873% [2843 1883]\n",
      "Shuffling training features and labels - 66..\n",
      " ... progress: In \"Epoch\" 66 of 100, mini batch 34500 of 51800\n",
      "\n",
      "After \"Epoch\" 67 of 100, mini batch 34706 of 51800\n",
      "  TRAIN cost/acc:0.1354/93.5252% [2658 2068], TEST cost/acc:3.2543/52.3487% [2701 2025]\n",
      "Shuffling training features and labels - 67..\n",
      " ... progress: In \"Epoch\" 67 of 100, mini batch 35000 of 51800\n",
      "\n",
      "After \"Epoch\" 68 of 100, mini batch 35224 of 51800\n",
      "  TRAIN cost/acc:0.1482/93.3136% [2698 2028], TEST cost/acc:3.3690/52.4757% [2843 1883]\n",
      "Shuffling training features and labels - 68..\n",
      " ... progress: In \"Epoch\" 68 of 100, mini batch 35500 of 51800\n",
      "\n",
      "After \"Epoch\" 69 of 100, mini batch 35742 of 51800\n",
      "  TRAIN cost/acc:0.1548/93.0385% [2717 2009], TEST cost/acc:3.2450/53.2162% [2932 1794]\n",
      "Shuffling training features and labels - 69..\n",
      " ... progress: In \"Epoch\" 69 of 100, mini batch 36000 of 51800\n",
      "\n",
      "After \"Epoch\" 70 of 100, mini batch 36260 of 51800\n",
      "  TRAIN cost/acc:0.1393/93.4617% [2641 2085], TEST cost/acc:3.3089/51.3330% [2633 2093]\n",
      "Shuffling training features and labels - 70..\n",
      " ... progress: In \"Epoch\" 70 of 100, mini batch 36500 of 51800\n",
      "\n",
      "After \"Epoch\" 71 of 100, mini batch 36778 of 51800\n",
      "  TRAIN cost/acc:0.1362/93.6733% [2735 1991], TEST cost/acc:3.4246/51.5023% [2861 1865]\n",
      "Shuffling training features and labels - 71..\n",
      " ... progress: In \"Epoch\" 71 of 100, mini batch 37000 of 51800\n",
      "\n",
      "After \"Epoch\" 72 of 100, mini batch 37296 of 51800\n",
      "  TRAIN cost/acc:0.1453/93.2078% [2773 1953], TEST cost/acc:3.3966/54.3165% [3216 1510]\n",
      "Shuffling training features and labels - 72..\n",
      " ... progress: In \"Epoch\" 72 of 100, mini batch 37500 of 51800\n",
      "\n",
      "After \"Epoch\" 73 of 100, mini batch 37814 of 51800\n",
      "  TRAIN cost/acc:0.1351/93.7791% [2692 2034], TEST cost/acc:3.3196/51.5235% [2648 2078]\n",
      "Shuffling training features and labels - 73..\n",
      " ... progress: In \"Epoch\" 73 of 100, mini batch 38000 of 51800\n",
      "\n",
      "After \"Epoch\" 74 of 100, mini batch 38332 of 51800\n",
      "  TRAIN cost/acc:0.1300/94.2023% [2690 2036], TEST cost/acc:3.4799/51.2907% [2785 1941]\n",
      "Shuffling training features and labels - 74..\n",
      " ... progress: In \"Epoch\" 74 of 100, mini batch 38500 of 51800\n",
      "\n",
      "After \"Epoch\" 75 of 100, mini batch 38850 of 51800\n",
      "  TRAIN cost/acc:0.1200/94.5197% [2695 2031], TEST cost/acc:3.5180/52.0102% [2825 1901]\n",
      "Shuffling training features and labels - 75..\n",
      " ... progress: In \"Epoch\" 75 of 100, mini batch 39000 of 51800\n",
      "\n",
      "After \"Epoch\" 76 of 100, mini batch 39368 of 51800\n",
      "  TRAIN cost/acc:0.1139/94.8159% [2659 2067], TEST cost/acc:3.7110/52.2006% [2862 1864]\n",
      "Shuffling training features and labels - 76..\n",
      " ... progress: In \"Epoch\" 76 of 100, mini batch 39500 of 51800\n",
      "\n",
      "After \"Epoch\" 77 of 100, mini batch 39886 of 51800\n",
      "  TRAIN cost/acc:0.1330/93.9484% [2720 2006], TEST cost/acc:3.6336/51.9890% [2818 1908]\n",
      "Shuffling training features and labels - 77..\n",
      " ... progress: In \"Epoch\" 77 of 100, mini batch 40000 of 51800\n",
      "\n",
      "After \"Epoch\" 78 of 100, mini batch 40404 of 51800\n",
      "  TRAIN cost/acc:0.1186/94.7947% [2626 2100], TEST cost/acc:3.2796/52.8142% [2783 1943]\n",
      "Shuffling training features and labels - 78..\n",
      " ... progress: In \"Epoch\" 78 of 100, mini batch 40500 of 51800\n",
      "\n",
      "After \"Epoch\" 79 of 100, mini batch 40922 of 51800\n",
      "  TRAIN cost/acc:0.1204/94.4773% [2659 2067], TEST cost/acc:3.4342/51.4812% [2760 1966]\n",
      "Shuffling training features and labels - 79..\n",
      " ... progress: In \"Epoch\" 79 of 100, mini batch 41000 of 51800\n",
      "\n",
      "After \"Epoch\" 80 of 100, mini batch 41440 of 51800\n",
      "  TRAIN cost/acc:0.1102/95.0275% [2625 2101], TEST cost/acc:3.7626/51.8832% [2795 1931]\n",
      "Shuffling training features and labels - 80..\n",
      " ... progress: In \"Epoch\" 80 of 100, mini batch 41500 of 51800\n",
      "\n",
      "After \"Epoch\" 81 of 100, mini batch 41958 of 51800\n",
      "  TRAIN cost/acc:0.1193/94.4562% [2656 2070], TEST cost/acc:3.7913/51.8409% [2707 2019]\n",
      "Shuffling training features and labels - 81..\n",
      " ... progress: In \"Epoch\" 81 of 100, mini batch 42000 of 51800\n",
      "\n",
      "After \"Epoch\" 82 of 100, mini batch 42476 of 51800\n",
      "  TRAIN cost/acc:0.0995/95.3237% [2669 2057], TEST cost/acc:3.6025/52.4545% [2738 1988]\n",
      "Shuffling training features and labels - 82..\n",
      " ... progress: In \"Epoch\" 82 of 100, mini batch 42500 of 51800\n",
      "\n",
      "After \"Epoch\" 83 of 100, mini batch 42994 of 51800\n",
      "  TRAIN cost/acc:0.1046/95.4084% [2649 2077], TEST cost/acc:3.4469/52.0313% [2800 1926]\n",
      "Shuffling training features and labels - 83..\n",
      " ... progress: In \"Epoch\" 83 of 100, mini batch 43000 of 51800\n",
      " ... progress: In \"Epoch\" 83 of 100, mini batch 43500 of 51800\n",
      "\n",
      "After \"Epoch\" 84 of 100, mini batch 43512 of 51800\n",
      "  TRAIN cost/acc:0.1035/95.4507% [2667 2059], TEST cost/acc:3.6310/52.5603% [2935 1791]\n",
      "Shuffling training features and labels - 84..\n",
      " ... progress: In \"Epoch\" 84 of 100, mini batch 44000 of 51800\n",
      "\n",
      "After \"Epoch\" 85 of 100, mini batch 44030 of 51800\n",
      "  TRAIN cost/acc:0.1239/94.0965% [2679 2047], TEST cost/acc:3.7174/52.7507% [3038 1688]\n",
      "Shuffling training features and labels - 85..\n",
      " ... progress: In \"Epoch\" 85 of 100, mini batch 44500 of 51800\n",
      "\n",
      "After \"Epoch\" 86 of 100, mini batch 44548 of 51800\n",
      "  TRAIN cost/acc:0.1019/95.4507% [2599 2127], TEST cost/acc:3.9709/51.2696% [2692 2034]\n",
      "Shuffling training features and labels - 86..\n",
      " ... progress: In \"Epoch\" 86 of 100, mini batch 45000 of 51800\n",
      "\n",
      "After \"Epoch\" 87 of 100, mini batch 45066 of 51800\n",
      "  TRAIN cost/acc:0.0928/95.6199% [2629 2097], TEST cost/acc:3.8967/51.7986% [2735 1991]\n",
      "Shuffling training features and labels - 87..\n",
      " ... progress: In \"Epoch\" 87 of 100, mini batch 45500 of 51800\n",
      "\n",
      "After \"Epoch\" 88 of 100, mini batch 45584 of 51800\n",
      "  TRAIN cost/acc:0.1020/95.1333% [2666 2060], TEST cost/acc:3.6888/52.5391% [2872 1854]\n",
      "Shuffling training features and labels - 88..\n",
      " ... progress: In \"Epoch\" 88 of 100, mini batch 46000 of 51800\n",
      "\n",
      "After \"Epoch\" 89 of 100, mini batch 46102 of 51800\n",
      "  TRAIN cost/acc:0.1164/95.1544% [2687 2039], TEST cost/acc:3.3944/53.4278% [2928 1798]\n",
      "Shuffling training features and labels - 89..\n",
      " ... progress: In \"Epoch\" 89 of 100, mini batch 46500 of 51800\n",
      "\n",
      "After \"Epoch\" 90 of 100, mini batch 46620 of 51800\n",
      "  TRAIN cost/acc:0.1006/95.3660% [2685 2041], TEST cost/acc:4.0126/53.4490% [3057 1669]\n",
      "Shuffling training features and labels - 90..\n",
      " ... progress: In \"Epoch\" 90 of 100, mini batch 47000 of 51800\n",
      "\n",
      "After \"Epoch\" 91 of 100, mini batch 47138 of 51800\n",
      "  TRAIN cost/acc:0.1084/95.4718% [2672 2054], TEST cost/acc:3.9586/53.4702% [2924 1802]\n",
      "Shuffling training features and labels - 91..\n",
      " ... progress: In \"Epoch\" 91 of 100, mini batch 47500 of 51800\n",
      "\n",
      "After \"Epoch\" 92 of 100, mini batch 47656 of 51800\n",
      "  TRAIN cost/acc:0.0812/96.3182% [2620 2106], TEST cost/acc:4.1369/52.9835% [2825 1901]\n",
      "Shuffling training features and labels - 92..\n",
      " ... progress: In \"Epoch\" 92 of 100, mini batch 48000 of 51800\n",
      "\n",
      "After \"Epoch\" 93 of 100, mini batch 48174 of 51800\n",
      "  TRAIN cost/acc:0.0937/95.7892% [2617 2109], TEST cost/acc:4.0916/52.8142% [2819 1907]\n",
      "Shuffling training features and labels - 93..\n",
      " ... progress: In \"Epoch\" 93 of 100, mini batch 48500 of 51800\n",
      "\n",
      "After \"Epoch\" 94 of 100, mini batch 48692 of 51800\n",
      "  TRAIN cost/acc:0.0962/95.7258% [2638 2088], TEST cost/acc:3.9628/53.0047% [2874 1852]\n",
      "Shuffling training features and labels - 94..\n",
      " ... progress: In \"Epoch\" 94 of 100, mini batch 49000 of 51800\n",
      "\n",
      "After \"Epoch\" 95 of 100, mini batch 49210 of 51800\n",
      "  TRAIN cost/acc:0.0913/95.8315% [2611 2115], TEST cost/acc:4.3442/52.6238% [2826 1900]\n",
      "Shuffling training features and labels - 95..\n",
      " ... progress: In \"Epoch\" 95 of 100, mini batch 49500 of 51800\n",
      "\n",
      "After \"Epoch\" 96 of 100, mini batch 49728 of 51800\n",
      "  TRAIN cost/acc:0.0888/96.1278% [2639 2087], TEST cost/acc:4.2300/52.3487% [2833 1893]\n",
      "Shuffling training features and labels - 96..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... progress: In \"Epoch\" 96 of 100, mini batch 50000 of 51800\n",
      "\n",
      "After \"Epoch\" 97 of 100, mini batch 50246 of 51800\n",
      "  TRAIN cost/acc:0.1158/94.8582% [2579 2147], TEST cost/acc:4.0228/51.9467% [2666 2060]\n",
      "Shuffling training features and labels - 97..\n",
      " ... progress: In \"Epoch\" 97 of 100, mini batch 50500 of 51800\n",
      "\n",
      "After \"Epoch\" 98 of 100, mini batch 50764 of 51800\n",
      "  TRAIN cost/acc:0.1029/95.3237% [2615 2111], TEST cost/acc:4.2083/51.6928% [2758 1968]\n",
      "Shuffling training features and labels - 98..\n",
      " ... progress: In \"Epoch\" 98 of 100, mini batch 51000 of 51800\n",
      "\n",
      "After \"Epoch\" 99 of 100, mini batch 51282 of 51800\n",
      "  TRAIN cost/acc:0.0839/96.4029% [2612 2114], TEST cost/acc:4.1910/51.6293% [2677 2049]\n",
      "Shuffling training features and labels - 99..\n",
      " ... progress: In \"Epoch\" 99 of 100, mini batch 51500 of 51800\n",
      "\n",
      "After \"Epoch\" 100 of 100, mini batch 51800 of 51800\n",
      "  TRAIN cost/acc:0.0845/96.5510% [2619 2107], TEST cost/acc:4.4877/53.5336% [2953 1773]\n",
      "\n",
      "FINISHED\n",
      "  TRAIN cost/acc:0.0845/96.5510% [2619 2107], TEST cost/acc:4.4877/53.5336% [2953 1773]\n",
      "TRAINING took 277.82975509302923 seconds.\n"
     ]
    }
   ],
   "source": [
    "time_start = timer()\n",
    "epoch = 0\n",
    "for mini_batch in range(1, total_mini_batches+1):\n",
    "    batch_inputs, batch_labels = getTrainMiniBatch(mini_batch_size)\n",
    "    sess.run([train, accuracy], feed_dict={X: batch_inputs, \n",
    "                                           labels: batch_labels,\n",
    "                                           keep_prob_in: keep_prob_in_train,\n",
    "                                           keep_prob_hid: keep_prob_hid_train})\n",
    "    if ((epoch == 0) and (mini_batch % 100 == 0) and (mini_batch <= 1000)):\n",
    "        printStats(' ... progress: In \"Epoch\" {} of {}, mini batch {} of {}'.format(epoch, epochs, mini_batch, total_mini_batches))\n",
    "    if (((epoch > 0) or (mini_batch > 1000)) and (mini_batch % 500 == 0)):\n",
    "        print(' ... progress: In \"Epoch\" {} of {}, mini batch {} of {}'.format(epoch, epochs, mini_batch, total_mini_batches))\n",
    "        \n",
    "    if (mini_batch % mini_batches_per_epoch == 0):\n",
    "        epoch += 1\n",
    "        printStats('\\nAfter \"Epoch\" {} of {}, mini batch {} of {}'.format(epoch, epochs, mini_batch, total_mini_batches))\n",
    "        \n",
    "training_time = timer()-time_start\n",
    "printStats(\"\\nFINISHED\")\n",
    "print(\"TRAINING took {} seconds.\".format(training_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:endre-tf]",
   "language": "python",
   "name": "conda-env-endre-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
